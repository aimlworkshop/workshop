{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Workshop\n",
    "In this workshop, we are going to train a model to predict the numerical values of hand-written digits using supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn\n",
    "# pip install numpy==1.23.5\n",
    "# pip install scikit-learn\n",
    "# python version: 3.9.6\n",
    "# pip install gymnasium\n",
    "# pip install \"gymnasium[toy-text]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shows the distribution of data in array data. Data must be an array of integers.\n",
    "\"\"\"\n",
    "def distributionOfData(data):\n",
    "    # Define bins\n",
    "    bin_edges = np.arange(0, 11, 1)  # Bin edges at integer intervals (-4 to 4)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # Compute bin centers\n",
    "\n",
    "    # Create the histogram\n",
    "    plt.hist(data, bins=bin_edges, color='blue', edgecolor='black', alpha=0.7, label=\"Data Distribution\")\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Value Ranges (Standard Deviations)', fontsize=12)\n",
    "    plt.ylabel('Frequency (Count of Data Points)', fontsize=12)\n",
    "    plt.title('Histogram of Randomly Generated Data', fontsize=14)\n",
    "\n",
    "    # Set x-axis ticks at bin centers\n",
    "    plt.xticks(bin_centers, labels=[f\"{x}\" for x in bin_edges[:-1]])\n",
    "\n",
    "    # Add grid for better readability\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Shows the images of digits used in the data set.\n",
    "\"\"\"\n",
    "def showVisualDigitsData(X_data, y_data, digit=0):\n",
    "    # Print data\n",
    "    print(\"Example of Data:\")\n",
    "\n",
    "    indices_less_than_max = np.where(y_data == digit)\n",
    "\n",
    "    plt.imshow(X_data[indices_less_than_max][0].reshape(8, 8), cmap=\"gray\")\n",
    "    plt.title(f\"Example Image (Label: {y_data[indices_less_than_max][0]})\")\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Shows numerical representation of each digit. Each digit is represented as a len-64 array with each value ranging between 0 an 16 where 0\n",
    "correlates to black and 16 correlates to white.\n",
    "\"\"\"\n",
    "def showNumericalDigitsData(X_data, y_data):\n",
    "    for i in range(3):\n",
    "        print(f\"Y-value: {X_data[i]}\")\n",
    "        print(f\"X-Value: {y_data.data[i]}\\n\")\n",
    "\n",
    "\"\"\"\n",
    "Filters the dataset to include digits < max_val\n",
    "\"\"\"\n",
    "def filteredDigits(sample_fraction=0.2):\n",
    "    digits = load_digits()\n",
    "    y = digits.target\n",
    "    \n",
    "    # Find indices where labels are even\n",
    "    even_indices = np.where(y % 2 == 0)[0]\n",
    "    \n",
    "    # Find indices where labels are odd\n",
    "    odd_indices = np.where(y % 2 == 1)[0]\n",
    "    \n",
    "    # Select 20% of each odd digit class\n",
    "    selected_odd_indices = []\n",
    "    for odd_digit in np.unique(y[odd_indices]):\n",
    "        digit_indices = np.where(y == odd_digit)[0]\n",
    "        sample_size = max(1, int(len(digit_indices) * sample_fraction))\n",
    "        selected_odd_indices.extend(np.random.choice(digit_indices, size=sample_size, replace=False))\n",
    "    \n",
    "    # Combine even indices with selected odd indices\n",
    "    selected_indices = np.concatenate([even_indices, selected_odd_indices])\n",
    "    \n",
    "    return digits.data[selected_indices], digits.target[selected_indices]\n",
    "\n",
    "\"\"\"\n",
    "Gets all the digits.\n",
    "\"\"\"\n",
    "def allDigits():\n",
    "    digits = load_digits()\n",
    "    return digits.data, digits.target\n",
    "\n",
    "\"\"\"\n",
    "Creates the supervised model. no-print means no statistics for each epoch will be printed\n",
    "\"\"\"\n",
    "def supervisedModel(X_train, X_test, y_test, y_train, epochs=10, batch_size=64, no_print=False):\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Define MLP model (warm_start=True allows incremental training)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=1, warm_start=True, verbose=False, batch_size=batch_size)\n",
    "\n",
    "    # Lists to store accuracy values\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    epoch_times = []  # List to store epoch times\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()  # Start time of the epoch\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        \n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "        if not (no_print):\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Training Accuracy: {train_acc:.4f}, Testing Accuracy: {test_acc:.4f}\")\n",
    "        end_time = time.time()  # End time of the epoch\n",
    "        epoch_time = end_time - start_time  # Time taken for the epoch\n",
    "        epoch_times.append(epoch_time)  # Store epoch time\n",
    "    return model, train_accuracies, test_accuracies, epoch_times\n",
    "\n",
    "\"\"\"\n",
    "Generate first round data\n",
    "\"\"\"\n",
    "def firstRoundData():\n",
    "    X_data, y_data = filteredDigits()\n",
    "    X_train, _, y_train, _ = train_test_split(X_data, y_data, test_size=0.2)\n",
    "    X_test, y_test = allDigits()\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\"\"\"\n",
    "Graphs test vs training loss.\n",
    "\"\"\"\n",
    "def graphAccuracies(train_accuracies, test_accuracies):\n",
    "    epochs = range(1, len(train_accuracies) + 1)  # Create an epoch range\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", marker='o')\n",
    "    plt.plot(epochs, test_accuracies, label=\"Testing Accuracy\", marker='s')\n",
    "    \n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training vs Testing Accuracy Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Shows images of the correctly predicted digits.\n",
    "\"\"\"\n",
    "def showCorrectPredictions(model, X_test, y_test):\n",
    "    model_preds = model.predict(X_test)\n",
    "    correct_indices = np.where(model_preds == y_test)[0][:10]  # Select 10 correctly classified digits\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(X_test[correct_indices[i]].reshape(8, 8), cmap='gray')\n",
    "        ax.set_title(f\"Pred: {model_preds[correct_indices[i]]}, True: {y_test[correct_indices[i]]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Shows images of the incorrectly predicted digits.\n",
    "\"\"\"\n",
    "def showIncorrectPredictions(model, X_test, y_test):\n",
    "    model_preds = model.predict(X_test)\n",
    "    incorrect_indices = np.where(model_preds != y_test)[0][:10]  # Select 10 correctly classified digits\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(X_test[incorrect_indices[i]].reshape(8, 8), cmap='gray')\n",
    "        ax.set_title(f\"Pred: {model_preds[incorrect_indices[i]]}, True: {y_test[incorrect_indices[i]]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Creates feature importance graph.\n",
    "\"\"\"\n",
    "def showFeatureImportance(model, X_test, y_test):\n",
    "    \n",
    "    # Assuming 'model' is your trained MLPClassifier model\n",
    "    result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "    # Get the feature importances\n",
    "    importances = result.importances_mean\n",
    "\n",
    "    norm_importances = (importances - np.min(importances)) / (np.max(importances) - np.min(importances))\n",
    "\n",
    "    importance_matrix = norm_importances.reshape(8, 8)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    cax = ax.matshow(importance_matrix, cmap='Blues')  # Using the Blues colormap\n",
    "\n",
    "    # Add colorbar to the plot\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set axis labels (just for clarity, with indices 1 to 8 for both X and Y)\n",
    "    ax.set_xticks(np.arange(8))\n",
    "    ax.set_yticks(np.arange(8))\n",
    "    ax.set_xticklabels(np.arange(1, 9))\n",
    "    ax.set_yticklabels(np.arange(1, 9))\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(\"Feature Importance Heatmap (Permutation Importance)\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Compares the average time per epoch, the max train accuracy, and the max test accuracy across many batch sizes.\n",
    "\"\"\"\n",
    "def compareBatchSizes(X_train, X_test, y_test, y_train, batch_sizes):\n",
    "    epoch_times_list = []\n",
    "    total_times_list = []\n",
    "    train_accuracies_list = []\n",
    "    test_accuracies_list = []\n",
    "    idx = []\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        _, train_accuracies, test_accuracies, epoch_times = supervisedModel(X_train, X_test, y_test, y_train, epochs=10, batch_size=batch_size, no_print=True)\n",
    "        epoch_times_list.append(sum(epoch_times)/len(epoch_times))\n",
    "        total_times_list.append(sum(epoch_times))\n",
    "        test_accuracies_list.append(max(test_accuracies))\n",
    "        train_accuracies_list.append(max(train_accuracies))\n",
    "        idx.append(batch_size)\n",
    "\n",
    "    createPlot(idx, epoch_times_list, \"# Batches\", \"Time (sec)\", \"Average Training Time per Batch #\")\n",
    "    createPlot(idx, train_accuracies_list, \"# Batches\", \"Max Train Accuracy\", \"Max Train Accuracy per Batch #\")\n",
    "    createPlot(idx, test_accuracies_list, \"# Batches\", \"Max Test Accuracy\", \"Max Test Accuracy per Batch #\")\n",
    "    createPlot(idx, total_times_list, \"# Batches\", \"Total Training Time (sec)\", \"Total Training Time per Batch #\")\n",
    "\n",
    "\"\"\"\n",
    "Helper function to create plots.\n",
    "\"\"\"\n",
    "def createPlot(x, y, xlabel, ylabel, title):\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step for the model training process is to gather the data. Run the cell below to get the x and y data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = firstRoundData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let's peek at the data. Run the function below to see the x and y data. Feel free to change the digit variable to see the example images of each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code\n",
    "digit = 9\n",
    "showVisualDigitsData(X_test, y_test, digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to remember that at the core, models are a series of mathematical functions. Because of this, the data input into the model must be numerical. Please write code to see how the images are converted from a digital to numerical representation. Hint: use the showNumericalDigitsData function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the images converted to a numerical representation? Hint: Each number describes a pixel on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Training Supervised Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to train the model. Peek at the supervisedModel function to see what model we use and how we train the model. What model do we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_accuracies, test_accuracies, epoch_times= supervisedModel(X_train, X_test, y_test, y_train, epochs=10, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has trained, let's look into the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function below to see what the model's testing and training accuracy are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphAccuracies(train_accuracies, test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the model is not performing well? Why do you we think this is the case? Let's debug by looking at the training and testing data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributionOfData(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the distribution of the testing data now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the issue? Why is it causing the model to perform badly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the issue, let's fix the data. Ensure to do a 80/20 split of the testing and training data. Look into the firstRoundData function for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need the testing/training data split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, following similar steps to above, train the model and plot the testing and training data against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is the model performing now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep dive into the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the below functions to see the correct and incorrect predictions that the model makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in functions appropriately \n",
    "showCorrectPredictions(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in functions appropriately \n",
    "showIncorrectPredictions(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also peek into the feature importance. This will show us how much importance the model places on each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in functions appropriately \n",
    "showFeatureImportance(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think some pixels have more importance than others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the results. How is the model performing? Are the incorrect predictions blatantly incorrect, or are they reasonable mistakes? What are some ways we can make the model perform even better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn: Try different batch sizes. Use the compareBatchSizes() function to see how batch size affects model performance (latency and accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compareBatchSizes() missing 5 required positional arguments: 'X_train', 'X_test', 'y_test', 'y_train', and 'batch_sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Fill in function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcompareBatchSizes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: compareBatchSizes() missing 5 required positional arguments: 'X_train', 'X_test', 'y_test', 'y_train', and 'batch_sizes'"
     ]
    }
   ],
   "source": [
    "### Fill in function\n",
    "compareBatchSizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What seems to be the optimal batch size? What parameters are you optimizing on (latency vs accuracy)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn\n",
    "# pip install numpy==1.23.5\n",
    "# pip install scikit-learn\n",
    "# python version: 3.9.6\n",
    "# pip install gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shows the distribution of data in array data. Data must be an array of integers.\n",
    "\"\"\"\n",
    "def distributionOfData(data):\n",
    "    # Define bins\n",
    "    bin_edges = np.arange(0, 11, 1)  # Bin edges at integer intervals (-4 to 4)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # Compute bin centers\n",
    "\n",
    "    # Create the histogram\n",
    "    plt.hist(data, bins=bin_edges, color='blue', edgecolor='black', alpha=0.7, label=\"Data Distribution\")\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Value Ranges (Standard Deviations)', fontsize=12)\n",
    "    plt.ylabel('Frequency (Count of Data Points)', fontsize=12)\n",
    "    plt.title('Histogram of Randomly Generated Data', fontsize=14)\n",
    "\n",
    "    # Set x-axis ticks at bin centers\n",
    "    plt.xticks(bin_centers, labels=[f\"{x}\" for x in bin_edges[:-1]])\n",
    "\n",
    "    # Add grid for better readability\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Shows the images of digits used in the data set.\n",
    "\"\"\"\n",
    "def showVisualDigitsData(X_data, y_data):\n",
    "    # Print data\n",
    "    print(\"Example of Data:\")\n",
    "\n",
    "    plt.imshow(X_data[0].reshape(8, 8), cmap=\"gray\")\n",
    "    plt.title(f\"Example Image (Label: {y_data[0]})\")\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Shows numerical representation of each digit. Each digit is represented as a len-64 array with each value ranging between 0 an 16 where 0\n",
    "correlates to black and 16 correlates to white.\n",
    "\"\"\"\n",
    "def showNumericalDigitsData(X_data, y_data):\n",
    "    for i in range(3):\n",
    "        print(f\"Y-value: {X_data[i]}\")\n",
    "        print(f\"X-Value: {y_data.data[i]}\\n\")\n",
    "\n",
    "\"\"\"\n",
    "Filters the dataset to include digits < max_val\n",
    "\"\"\"\n",
    "def filteredDigits(max_val=5):\n",
    "        # Load the digits dataset\n",
    "    digits = load_digits()\n",
    "\n",
    "    # Extract the labels (target) from the dataset\n",
    "    y = digits.target\n",
    "\n",
    "    # Use np.where to find the indices of labels that are less than 5\n",
    "    indices_less_than_max = np.where(y < max_val)\n",
    "    \n",
    "    return digits.data[indices_less_than_max], digits.target[indices_less_than_max]\n",
    "\n",
    "\"\"\"\n",
    "Gets all the digits.\n",
    "\"\"\"\n",
    "def allDigits():\n",
    "    digits = load_digits()\n",
    "    return digits.data, digits.target\n",
    "\n",
    "\"\"\"\n",
    "Creates the supervised model. no-print means no statistics for each epoch will be printed\n",
    "\"\"\"\n",
    "def supervisedModel(X_train, X_test, y_test, y_train, epochs=10, batch_size=64, no_print=False):\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Define MLP model (warm_start=True allows incremental training)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=1, warm_start=True, verbose=False, batch_size=batch_size)\n",
    "\n",
    "    # Lists to store accuracy values\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    epoch_times = []  # List to store epoch times\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()  # Start time of the epoch\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        \n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "        if not (no_print):\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Training Accuracy: {train_acc:.4f}, Testing Accuracy: {test_acc:.4f}\")\n",
    "        end_time = time.time()  # End time of the epoch\n",
    "        epoch_time = end_time - start_time  # Time taken for the epoch\n",
    "        epoch_times.append(epoch_time)  # Store epoch time\n",
    "    return model, train_accuracies, test_accuracies, epoch_times\n",
    "\n",
    "\"\"\"\n",
    "Graphs test vs training loss.\n",
    "\"\"\"\n",
    "def graphAccuracies(train_accuracies, test_accuracies):\n",
    "    epochs = range(1, len(train_accuracies) + 1)  # Create an epoch range\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", marker='o')\n",
    "    plt.plot(epochs, test_accuracies, label=\"Testing Accuracy\", marker='s')\n",
    "    \n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training vs Testing Accuracy Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Shows images of the correctly predicted digits.\n",
    "\"\"\"\n",
    "def showCorrectPredictions(model, X_test, y_test):\n",
    "    model_preds = model.predict(X_test)\n",
    "    correct_indices = np.where(model_preds == y_test)[0][:10]  # Select 10 correctly classified digits\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(X_test[correct_indices[i]].reshape(8, 8), cmap='gray')\n",
    "        ax.set_title(f\"Pred: {model_preds[correct_indices[i]]}, True: {y_test[correct_indices[i]]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Shows images of the incorrectly predicted digits.\n",
    "\"\"\"\n",
    "def showIncorrectPredictions(model, X_test, y_test):\n",
    "    model_preds = model.predict(X_test)\n",
    "    incorrect_indices = np.where(model_preds != y_test)[0][:10]  # Select 10 correctly classified digits\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(X_test[incorrect_indices[i]].reshape(8, 8), cmap='gray')\n",
    "        ax.set_title(f\"Pred: {model_preds[incorrect_indices[i]]}, True: {y_test[incorrect_indices[i]]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Creates feature importance graph.\n",
    "\"\"\"\n",
    "def showFeatureImportance(model, X_test, y_test):\n",
    "    \n",
    "    # Assuming 'model' is your trained MLPClassifier model\n",
    "    result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "    # Get the feature importances\n",
    "    importances = result.importances_mean\n",
    "\n",
    "    norm_importances = (importances - np.min(importances)) / (np.max(importances) - np.min(importances))\n",
    "\n",
    "    importance_matrix = norm_importances.reshape(8, 8)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    cax = ax.matshow(importance_matrix, cmap='Blues')  # Using the Blues colormap\n",
    "\n",
    "    # Add colorbar to the plot\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set axis labels (just for clarity, with indices 1 to 8 for both X and Y)\n",
    "    ax.set_xticks(np.arange(8))\n",
    "    ax.set_yticks(np.arange(8))\n",
    "    ax.set_xticklabels(np.arange(1, 9))\n",
    "    ax.set_yticklabels(np.arange(1, 9))\n",
    "\n",
    "    # Set title\n",
    "    ax.set_title(\"Feature Importance Heatmap (Permutation Importance)\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Compares the average time per epoch, the max train accuracy, and the max test accuracy across many batch sizes.\n",
    "\"\"\"\n",
    "def compareBatchSizes(X_train, X_test, y_test, y_train, batch_sizes):\n",
    "    epoch_times_list = []\n",
    "    total_times_list = []\n",
    "    train_accuracies_list = []\n",
    "    test_accuracies_list = []\n",
    "    idx = []\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        _, train_accuracies, test_accuracies, epoch_times = supervisedModel(X_train, X_test, y_test, y_train, epochs=10, batch_size=batch_size, no_print=True)\n",
    "        epoch_times_list.append(sum(epoch_times)/len(epoch_times))\n",
    "        total_times_list.append(sum(epoch_times))\n",
    "        test_accuracies_list.append(max(test_accuracies))\n",
    "        train_accuracies_list.append(max(train_accuracies))\n",
    "        idx.append(batch_size)\n",
    "\n",
    "    createPlot(idx, epoch_times_list, \"# Batches\", \"Time (sec)\", \"Average Training Time per Batch #\")\n",
    "    createPlot(idx, train_accuracies_list, \"# Batches\", \"Max Train Accuracy\", \"Max Train Accuracy per Batch #\")\n",
    "    createPlot(idx, test_accuracies_list, \"# Batches\", \"Max Test Accuracy\", \"Max Test Accuracy per Batch #\")\n",
    "    createPlot(idx, total_times_list, \"# Batches\", \"Total Training Time (sec)\", \"Total Training Time per Batch #\")\n",
    "\n",
    "\"\"\"\n",
    "Helper function to create plots.\n",
    "\"\"\"\n",
    "def createPlot(x, y, xlabel, ylabel, title):\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = filteredDigits()\n",
    "X_train, _, y_train, _ = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "X_test, y_test = allDigits()\n",
    "\n",
    "print(f\"Length of training data: {len(X_train)}\")\n",
    "print(f\"Length of testing data: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn: Show one of the digits using above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn: Show the numerical representations of the data. How is the image converted to a numerical representation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_accuracies, test_accuracies, epoch_times= supervisedModel(X_train, X_test, y_test, y_train, epochs=10, batch_size=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peek into the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphAccuracies(train_accuracies, test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is the model performing so badly? What can we fix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep dive into the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in functions appropriately \n",
    "showCorrectPredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in functions appropriately \n",
    "showIncorrectPredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in functions appropriately \n",
    "showFeatureImportance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn: Try different batch sizes. Use the above functions to see how batch size affects model performance (latency and accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
